<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10-blue?logo=python" />
  <img src="https://img.shields.io/badge/Prefect-3.0-blueviolet?logo=prefect" />
  <img src="https://img.shields.io/badge/DuckDB-0.10.2-yellow?logo=duckdb" />
  <img src="https://img.shields.io/badge/Pandas-2.1-green?logo=pandas" />
  <img src="https://img.shields.io/badge/LLM_Assisted-Enabled-orange?logo=openai" />
  <img src="https://img.shields.io/badge/Status-Operational-brightgreen?logo=github" />
  <img src="https://img.shields.io/github/license/NobelShaji/ai-assisted-etl" />
</p>


# AI-Assisted ETL Pipeline with DuckDB & Prefect

An end-to-end **AI-assisted ETL/ELT pipeline** that ingests NYC Taxi data, runs **LLM-style data cleaning & transformation logic**, validates schemas, and loads analytics- and ML-ready tables into **DuckDB**.

The goal of this project is to simulate how **modern ETL tools embed LLM/agent capabilities** to:
- Propose cleaning and transformation rules
- Generate reusable code
- Build features for analytics & ML
- Keep everything **local, free, and transparent**

> âœ… All components in this project are local & free: Python, DuckDB, Prefect, Pandas, Pandera.  
> No external LLM calls â€“ the â€œLLMâ€ is represented by a deterministic Python stub that logs prompts and returns code.

---

## ğŸ— Architecture (ASCII Overview)

Data flows through the pipeline in clearly defined layers:

```text
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  1. Ingest (Prefect Task) â”‚
         â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
         â”‚  Download NYC Yellow Taxi â”‚
         â”‚  CSV â†’ data/raw/         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  2. Bronze Layer           â”‚
         â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
         â”‚  CSV â†’ Parquet            â”‚
         â”‚  Basic type coercion      â”‚
         â”‚  data/bronze/taxi_sample  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  3. LLM-Assisted Transform â”‚
         â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
         â”‚  src/llm_assist.py        â”‚
         â”‚  - logs schema + goal     â”‚
         â”‚  - returns transform(df)  â”‚
         â”‚  â†’ cleaned DataFrame      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  4. Silver Layer           â”‚
         â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
         â”‚  pandera validation       â”‚
         â”‚  data/silver/taxi_sample  â”‚
         â”‚  DuckDB: silver.taxi_sampleâ”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  5. Gold / Features        â”‚
         â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
         â”‚  sql/04_ml_features_*.sql â”‚
         â”‚  DuckDB: gold.taxi_trip_  â”‚
         â”‚           features        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  6. Analytics & Modeling   â”‚
         â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
         â”‚  DuckDB SQL, notebooks,   â”‚
         â”‚  BI tools (optional)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


âš ï¸ Note: thatâ€™s a **markdown code block inside markdown**, so be sure you keep both pairs of triple backticks exactly as shown (outer ```md and inner ```text).

---

## 2ï¸âƒ£ Mermaid Diagram (B)

Right **under** that ASCII section, paste this Mermaid version:

```md
## ğŸ§­ Architecture (Mermaid Diagram)

```mermaid
flowchart LR
    subgraph Raw["Raw Layer (data/raw)"]
        R1["NYC Yellow Taxi CSV
        data/raw/taxi_sample.csv"]
    end

    subgraph Bronze["Bronze Layer (data/bronze)"]
        B1["Parquet: taxi_sample.parquet"]
    end

    subgraph LLM["LLM-Assisted Transform"]
        L1["suggest_cleaning_code(schema, goal)
â†’ returns transform(df) code"]
        L2["transform(df) applied in Prefect task"]
    end

    subgraph Silver["Silver Layer (data/silver + DuckDB)"]
        S1["Validated Parquet:
data/silver/taxi_sample_clean.parquet"]
        S2["DuckDB table:
silver.taxi_sample"]
    end

    subgraph Gold["Gold / Features (DuckDB)"]
        G1["gold.taxi_trip_features
(sql/04_ml_features_materialized.sql)"]
    end

    subgraph Analytics["Analytics & ML"]
        A1["SQL: 01/02/03_*.sql
(analytics, features, data quality)"]
        A2["Notebooks / BI tools (optional)"]
    end

    R1 --> B1
    B1 --> L1 --> L2 --> S1 --> S2 --> G1 --> A1 --> A2


Again: keep the nested backticks exactly like that.

---

## Quick sanity check (what your README top will look like)

Rough order:

```md
# AI-Assisted ETL Pipeline with DuckDB & Prefect

<p align="center">
  ...badges...
</p>

## ğŸ— Architecture (ASCII Overview)
...ASCII diagram...

## ğŸ§­ Architecture (Mermaid Diagram)
...Mermaid code...

## ğŸ” High-Level Overview
...your existing section...

## ğŸ” High-Level Overview

**Data flow:**

1. **Ingest (Raw â†’ CSV)**  
   - Download sample NYC Yellow Taxi trips CSV into `data/raw/taxi_sample.csv`.

2. **Bronze Layer (Raw â†’ Parquet)**  
   - Basic type coercion & persistence in `data/bronze/taxi_sample.parquet`.

3. **LLM-Assisted Transform (Bronze â†’ Cleaned DataFrame)**  
   - A stub function (`suggest_cleaning_code`) mimics an LLM:
     - Logs the input schema + goal to `docs/llm_logs/`
     - Returns a Python code string with a `transform(df)` function
   - The flow `exec`s that code and applies `transform(df)` to the Bronze data.

4. **Silver Layer (Validated Parquet)**  
   - Schema validation with **pandera**.
   - Writes `data/silver/taxi_sample_clean.parquet`.
   - Loads into DuckDB as `silver.taxi_sample`.

5. **Gold Layer (Feature Table)**  
   - SQL in `sql/04_ml_features_materialized.sql` builds:
     - `gold.taxi_trip_features` with features like:
       - trip duration, speed, tip percentage
       - long-trip / high-fare flags
       - time-of-day buckets (morning/afternoon/evening/night)

6. **Analytics & Feature SQL**  
   - Example analytics & feature engineering queries:
     - `sql/01_analytics_examples.sql`
     - `sql/02_feature_engineering_examples.sql`
     - `sql/03_data_quality_checks.sql`

---

## ğŸ§± Tech Stack

- **Language:** Python 3.10
- **Orchestration:** [Prefect 3](https://docs.prefect.io/)
- **Warehouse / Query Engine:** [DuckDB](https://duckdb.org/)
- **DataFrame Engine:** pandas
- **Schema Validation:** pandera
- **Storage Layers:**
  - `data/raw`   â†’ landing / raw files
  - `data/bronze` â†’ lightly cleaned parquet
  - `data/silver` â†’ validated & cleaned parquet
  - `gold.*` tables in DuckDB

---

## ğŸ—‚ Project Structure

```bash
ai-assisted-etl/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ raw/        # raw CSV download
â”‚   â”œâ”€â”€ bronze/     # bronze parquet
â”‚   â”œâ”€â”€ silver/     # silver parquet
â”‚   â””â”€â”€ gold/       # (optional local exports)
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ llm_logs/
â”‚       â””â”€â”€ .gitkeep   # JSON logs of "LLM" suggestions
â”œâ”€â”€ orchestration/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ flow_ingest_transform.py  # main Prefect flow
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 01_analytics_examples.sql
â”‚   â”œâ”€â”€ 02_feature_engineering_examples.sql
â”‚   â”œâ”€â”€ 03_data_quality_checks.sql
â”‚   â””â”€â”€ 04_ml_features_materialized.sql
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.py         # config & paths
    â”œâ”€â”€ ingest.py         # download/read/write helpers
    â”œâ”€â”€ llm_assist.py     # "LLM" stub that returns cleaning code
    â”œâ”€â”€ validate.py       # pandera schema
    â””â”€â”€ warehouse.py      # DuckDB connection & schema helpers

